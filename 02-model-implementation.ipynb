{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass(model, input_shape=(1, 3, 64, 64), device='cuda'):\n",
    "    \"\"\"\n",
    "    Test a model with dummy data to ensure the forward pass works.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to test\n",
    "        input_shape: The shape of the input tensor (batch_size, channels, height, width)\n",
    "        device: The device to run the test on\n",
    "        \n",
    "    Returns:\n",
    "        output: The model output\n",
    "        output_shape: The shape of the output\n",
    "    \"\"\"\n",
    "    # Create a random tensor with the correct shape\n",
    "    x = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    # Move model to the device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform forward pass\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            output = model(x)\n",
    "            print(f\"Forward pass successful!\")\n",
    "            print(f\"Input shape: {x.shape}\")\n",
    "            print(f\"Output shape: {output.shape}\")\n",
    "            return output, output.shape\n",
    "        except Exception as e:\n",
    "            print(f\"Forward pass failed with error: {e}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count the number of trainable parameters in a model.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of trainable parameters\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#=============================================\n",
    "# 1. Baseline CNN for CIFAR-10\n",
    "#=============================================\n",
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Streamlined Baseline CNN for CIFAR-10 classification\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 3\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 4\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "#=============================================\n",
    "# 2. Squeeze and Excitation CNN for CIFAR-10\n",
    "#=============================================\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        # Squeeze operation\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        # Excitation operation\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        # Scale the input\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "\n",
    "class SECNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN with Squeeze-and-Excitation blocks for CIFAR-10\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SECNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.se1 = SEBlock(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.se2 = SEBlock(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.se3 = SEBlock(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.se4 = SEBlock(128)\n",
    "        \n",
    "        # Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # For saving attention maps\n",
    "        self.attention_maps = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Clear previous attention maps\n",
    "        self.attention_maps = []\n",
    "        \n",
    "        # Block 1\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.se1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.se2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = self.se3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 4\n",
    "        x = self.bn4(self.conv4(x))\n",
    "        x = self.se4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_attention_maps(self):\n",
    "        \"\"\"Hook function to extract SE attention weights\"\"\"\n",
    "        attention_maps = []\n",
    "        def hook_fn(module, input, output):\n",
    "            if isinstance(module, SEBlock):\n",
    "                b, c = input[0].size(0), input[0].size(1)\n",
    "                # Get the sigmoid attention weights\n",
    "                weights = module.fc(module.avg_pool(input[0]).view(b, c))\n",
    "                attention_maps.append(weights.detach().cpu())\n",
    "        \n",
    "        # Register hooks for all SE blocks\n",
    "        hooks = []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, SEBlock):\n",
    "                hooks.append(module.register_forward_hook(hook_fn))\n",
    "        \n",
    "        return attention_maps, hooks\n",
    "\n",
    "\n",
    "#=============================================\n",
    "# 3. Convolutional Block Attention Module (CBAM) CNN\n",
    "#=============================================\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel attention module for CBAM\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        # Shared MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction, kernel_size=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, kernel_size=1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = self.mlp(self.avg_pool(x))\n",
    "        max_out = self.mlp(self.max_pool(x))\n",
    "        out = torch.sigmoid(avg_out + max_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial attention module for CBAM\"\"\"\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        assert kernel_size in (3, 7), \"Kernel size must be 3 or 7\"\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        \n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = torch.sigmoid(self.conv(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    \"\"\"Convolutional Block Attention Module\"\"\"\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "        self.channel_att = ChannelAttention(channels, reduction)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Channel attention first\n",
    "        channel_att = self.channel_att(x)\n",
    "        x = x * channel_att\n",
    "        \n",
    "        # Then spatial attention\n",
    "        spatial_att = self.spatial_att(x)\n",
    "        x = x * spatial_att\n",
    "        \n",
    "        # Save attention map for visualization\n",
    "        return x, spatial_att\n",
    "\n",
    "\n",
    "class CBAMCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN with CBAM for CIFAR-10\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CBAMCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.cbam1 = CBAMBlock(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.cbam2 = CBAMBlock(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.cbam3 = CBAMBlock(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.cbam4 = CBAMBlock(128)\n",
    "        \n",
    "        # Classifier\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # For saving attention maps\n",
    "        self.attention_maps = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Clear previous attention maps\n",
    "        self.attention_maps = []\n",
    "        \n",
    "        # Block 1\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x_att, spatial_map1 = self.cbam1(x)\n",
    "        self.attention_maps.append(spatial_map1)\n",
    "        x = F.relu(x_att)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x_att, spatial_map2 = self.cbam2(x)\n",
    "        self.attention_maps.append(spatial_map2)\n",
    "        x = F.relu(x_att)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x_att, spatial_map3 = self.cbam3(x)\n",
    "        self.attention_maps.append(spatial_map3)\n",
    "        x = F.relu(x_att)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Block 4\n",
    "        x = self.bn4(self.conv4(x))\n",
    "        x_att, spatial_map4 = self.cbam4(x)\n",
    "        self.attention_maps.append(spatial_map4)\n",
    "        x = F.relu(x_att)\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def get_attention_maps(self):\n",
    "        \"\"\"Method to access collected attention maps\"\"\"\n",
    "        return self.attention_maps\n",
    "\n",
    "\n",
    "#=============================================\n",
    "# Helper Functions\n",
    "#=============================================\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in a model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def test_forward_pass(model, input_shape=(1, 3, 32, 32), device='cpu'):\n",
    "    \"\"\"\n",
    "    Test a model with dummy data to ensure the forward pass works.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to test\n",
    "        input_shape: The shape of the input tensor (batch_size, channels, height, width)\n",
    "        device: The device to run the test on\n",
    "        \n",
    "    Returns:\n",
    "        output: The model output\n",
    "        output_shape: The shape of the output\n",
    "    \"\"\"\n",
    "    # Create a random tensor with the correct shape\n",
    "    x = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    # Move model to the device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform forward pass\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            output = model(x)\n",
    "            print(f\"Forward pass successful!\")\n",
    "            print(f\"Input shape: {x.shape}\")\n",
    "            print(f\"Output shape: {output.shape}\")\n",
    "            return output, output.shape\n",
    "        except Exception as e:\n",
    "            print(f\"Forward pass failed with error: {e}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Baseline CNN:\n",
      "Forward pass successful!\n",
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "Output shape: torch.Size([1, 10])\n",
      "\n",
      "Testing SE-CNN:\n",
      "Forward pass successful!\n",
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "Output shape: torch.Size([1, 10])\n",
      "\n",
      "Testing CBAM-CNN:\n",
      "Forward pass successful!\n",
      "Input shape: torch.Size([1, 3, 32, 32])\n",
      "Output shape: torch.Size([1, 10])\n",
      "\n",
      "Parameter Counts:\n",
      "Baseline CNN: 259,338 parameters\n",
      "SE-CNN: 264,074 parameters\n",
      "CBAM-CNN: 264,466 parameters\n",
      "\n",
      "SE-CNN has 1.83% more parameters than baseline\n",
      "CBAM-CNN has 1.98% more parameters than baseline\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "baseline_model = BaselineCNN(num_classes=10)\n",
    "se_model = SECNN(num_classes=10)\n",
    "cbam_model = CBAMCNN(num_classes=10)\n",
    "\n",
    "# Test forward pass\n",
    "print(\"Testing Baseline CNN:\")\n",
    "test_forward_pass(baseline_model)\n",
    "\n",
    "print(\"\\nTesting SE-CNN:\")\n",
    "test_forward_pass(se_model)\n",
    "\n",
    "print(\"\\nTesting CBAM-CNN:\")\n",
    "test_forward_pass(cbam_model)\n",
    "\n",
    "# Count parameters\n",
    "print(\"\\nParameter Counts:\")\n",
    "print(f\"Baseline CNN: {count_parameters(baseline_model):,} parameters\")\n",
    "print(f\"SE-CNN: {count_parameters(se_model):,} parameters\")\n",
    "print(f\"CBAM-CNN: {count_parameters(cbam_model):,} parameters\")\n",
    "\n",
    "# Calculate parameter increase percentage\n",
    "baseline_params = count_parameters(baseline_model)\n",
    "se_params = count_parameters(se_model)\n",
    "cbam_params = count_parameters(cbam_model)\n",
    "\n",
    "print(f\"\\nSE-CNN has {(se_params - baseline_params) / baseline_params * 100:.2f}% more parameters than baseline\")\n",
    "print(f\"CBAM-CNN has {(cbam_params - baseline_params) / baseline_params * 100:.2f}% more parameters than baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
